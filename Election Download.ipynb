{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd08665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea70956c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BAYELSA': 'https://www.inecelectionresults.ng//elections/63f8f25b594e164f8146a213?state=6'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de29f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726c4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_links(driver: webdriver) -> List[Dict[str,str]]:\n",
    "    \"\"\"\n",
    "    Retrieves links for each state for the 2023 Nigerian presidential election.\n",
    "    \n",
    "    Args:\n",
    "    - driver: WebDriver object from Selenium.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of dictionaries containing state name and its corresponding link.\n",
    "    \n",
    "    \"\"\"\n",
    "    url = \"https://www.inecelectionresults.ng/pres/elections/63f8f25b594e164f8146a213?type=pres\"\n",
    "    driver.get(url)\n",
    "    time.sleep(15)\n",
    "    soup = bs(driver.page_source,'lxml')\n",
    "    states = {i.find('a').text:\"https://www.inecelectionresults.ng/\" +i.find('a')['href'] for i in soup.find('div',{'class':\"col-md-9\"}).find_all('div',{'class':'m-2 p-2 bg-light'})}\n",
    "    return states\n",
    "\n",
    "def get_lga_link():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - A list of dictionaries containing lgas name and its corresponding link for the current state.\n",
    "    \n",
    "    \"\"\"\n",
    "    time.sleep(20)\n",
    "    soup = bs(driver.page_source,'lxml')\n",
    "    lgas = {i.find('a').text:\"https://www.inecelectionresults.ng/\" +i.find('a')['href'] for i in soup.find_all('div',{'class':re.compile('m-2 p-2 bg-light')})}\n",
    "    \n",
    "    return lgas \n",
    "\n",
    "def get_lgas_links(driver: webdriver, state_url: str) -> List[Dict[str,str]]:\n",
    "    \"\"\"\n",
    "    Retrieves all lgas links for the current state\n",
    "    \n",
    "    Args:\n",
    "    - driver: WebDriver object from Selenium.\n",
    "    - state_url: state link\n",
    "    \n",
    "    Returns:\n",
    "    - A list of dictionaries containing lgas name and its corresponding link.\n",
    "    \n",
    "    \"\"\"\n",
    "    driver.get(state_url)\n",
    "    lgas = get_lga_link()\n",
    "    #in case the page didnt load before it tries to extract, it will retry the process (reason why we have two\n",
    "    #functions for this)\n",
    "    if len(lgas) <1:\n",
    "        lgas = get_lga_link()\n",
    "    return lgas\n",
    "\n",
    "\n",
    "def get_wards_links(driver: webdriver, lga_url: str) -> List[Dict[str,str]]:\n",
    "    \"\"\"\n",
    "    Retrieves all wards links for the current state and lga\n",
    "    \n",
    "    Args:\n",
    "    - driver: WebDriver object from Selenium.\n",
    "    - lga_url: lga link\n",
    "    \n",
    "    Returns:\n",
    "    - A list of dictionaries containing wards name and its corresponding link.\n",
    "    \n",
    "    \"\"\"\n",
    "    driver.get(lga_url)\n",
    "    time.sleep(15)\n",
    "    soup = bs(driver.page_source,'lxml')\n",
    "    wards = {i.find('a').text:\"https://www.inecelectionresults.ng/\" +i.find('a')['href'] for i in soup.find_all('div',{'class':re.compile('m-2 p-2 bg-light')})}\n",
    "    return wards\n",
    "\n",
    "def poll_unit_ward_section():\n",
    "    time.sleep(10)\n",
    "    #find the parent element that contains all PUs\n",
    "    html_ward = driver.find_element(By.XPATH, '/html/body/app-root/div/app-activated/div/div/div/div/app-election-lga/div/div/div/div/div[2]/div/div[2]/div[2]/div').get_attribute('innerHTML')\n",
    "    #find the container\n",
    "    div = bs(html_ward,'lxml').find('body')\n",
    "    #get immediate child of thr parent element\n",
    "    pus = div.findAll(\"div\" , recursive=False)\n",
    "    len_pu = len(pus)\n",
    "    return pus\n",
    "\n",
    "def file_src():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - the link to the file\n",
    "    \n",
    "    \"\"\"\n",
    "    time.sleep(5)\n",
    "    soup = bs(driver.page_source,'lxml')\n",
    "    urls = soup.iframe['src']\n",
    "    return urls\n",
    "\n",
    "def download_file(i):\n",
    "\n",
    "    filename = list(i.keys())[0].replace(':','').replace('/','')\n",
    "    \n",
    "    url_file = list(i.values())[0]\n",
    "    extension = url_file.rsplit('.')[-1]\n",
    "    response = requests.get(url_file)\n",
    "    \n",
    "    new_filename = f\"{filename}.{extension}\"\n",
    "    with open(new_filename, \"wb\")as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def scrape_all_pus_links(driver: webdriver, ward_url: str):\n",
    "    global links\n",
    "    driver.get(ward_url)\n",
    "    time.sleep(20)\n",
    "    #gets all PUs\n",
    "    try:\n",
    "        pus = poll_unit_ward_section()\n",
    "    except:\n",
    "        pus = poll_unit_ward_section()\n",
    "    #loop through each PU , selenium is used to click the button using the index\n",
    "    for idx,q in enumerate(pus):\n",
    "        try:\n",
    "            pu = ' '.join(q.text.split()[:-2])\n",
    "            current_url = driver.current_url\n",
    "            print(pu)\n",
    "            try:\n",
    "                time.sleep(10)\n",
    "                driver.find_element(By.XPATH,f'/html/body/app-root/div/app-activated/div/div/div/div/app-election-lga/div/div/div/div/div[2]/div/div[2]/div[2]/div/div[{idx+1}]/div/div[2]/button').click()\n",
    "            except:\n",
    "                time.sleep(15)\n",
    "                driver.find_element(By.XPATH,f'/html/body/app-root/div/app-activated/div/div/div/div/app-election-lga/div/div/div/div/div[2]/div/div[2]/div[2]/div/div[{idx+1}]/div/div[2]/button').click()\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                urls = file_src()\n",
    "            except:\n",
    "\n",
    "                urls = file_src()\n",
    "            \n",
    "#             download_file({pu:urls})\n",
    "            links.append({pu:urls})\n",
    "            \n",
    "        except:\n",
    "            print(f\"{q.text} count not be gotten\")\n",
    "        driver.get(current_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d581876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lga_data(i):\n",
    "    lgas = get_lgas_links(driver,i)\n",
    "    for k in lgas.keys():\n",
    "        wards = get_wards_links(driver,lgas[k])\n",
    "        for j in wards.keys():\n",
    "            x = scrape_all_pus_links(driver,wards[j])\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5152a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(single=None):\n",
    "    global driver\n",
    "    #open the webdriver\n",
    "    driver= webdriver.Chrome()\n",
    "    states = get_states_links(driver)\n",
    "    if single:\n",
    "        for i in states.keys():\n",
    "            get_lga_data(states[i])\n",
    "    else:\n",
    "        if single.upper in states:\n",
    "            get_lga_data(states[single.upper()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe9beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b407bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38219b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABIA PLOY XVIII PU Code: 01/01/01/035\n",
      "EZIAMA HIGH SCH. XI PU Code: 01/01/01/050\n",
      "ABIA PLOY XXVII PU Code: 01/01/01/044\n",
      " ABIA PLOY XXVII PU Code: 01/01/01/044 View result count not be gotten\n",
      "ABIA POLY XXVI PU Code: 01/01/01/043\n",
      "ABIA PLOY XXV PU Code: 01/01/01/042\n",
      "ABIA PLOY XXIV PU Code: 01/01/01/041\n",
      " ABIA PLOY XXIV PU Code: 01/01/01/041 View result count not be gotten\n",
      "ABIA PLOY XX PU Code: 01/01/01/037\n",
      " ABIA PLOY XX PU Code: 01/01/01/037 View result count not be gotten\n",
      "ABIA POLY XV PU Code: 01/01/01/032\n"
     ]
    }
   ],
   "source": [
    "main('BAYELSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca38e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all():\n",
    "    for link in links:\n",
    "        download_file(link)\n",
    "        print('downloaded ',link.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82415fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded  dict_keys(['RESTORATION DRIVE SQUARE PU Code: 06/04/01/018'])\n",
      "downloaded  dict_keys(['COMMUNITY GIRLS SEC SCHOOL, NEMBE PU Code: 06/04/01/017'])\n",
      "downloaded  dict_keys(['AMABEBE-OPO SQUARE PU Code: 06/04/01/016'])\n",
      "downloaded  dict_keys(['IDIBITIYE-ITIDION SQUARE PU Code: 06/04/01/015'])\n",
      "downloaded  dict_keys(['UBE MODEL SCHOOL, TOMBI NEMBE PU Code: 06/04/01/014'])\n",
      "downloaded  dict_keys(['MINGI XI SQUARE PU Code: 06/04/01/013'])\n",
      "downloaded  dict_keys(['KING KOKO PARK ROUND ABOUT SQUARE PU Code: 06/04/01/012'])\n",
      "downloaded  dict_keys(['AKPARANTA II OPEN SPACE PU Code: 06/04/01/011'])\n",
      "downloaded  dict_keys(['ISIKARA/EGWE EWOAMA/VILLAGE SQUARE PU Code: 06/04/01/010'])\n",
      "downloaded  dict_keys(['AKPARANTA/COMMUNITY SQUARE PU Code: 06/04/01/009'])\n",
      "downloaded  dict_keys(['TUBOPIRI/TUBOPIRI SQUARE PU Code: 06/04/01/008'])\n",
      "downloaded  dict_keys(['CH.AMAIN COMP/ST. LUKES NEMBE PU Code: 06/04/01/007'])\n",
      "downloaded  dict_keys(['CH.AMAIN COMP/UAC PU Code: 06/04/01/006'])\n",
      "downloaded  dict_keys(['MADIARA POLO/MADIARA SQUARE PU Code: 06/04/01/005'])\n",
      "downloaded  dict_keys(['OGIRIKI POLO/COMMUNITY SQUARE PU Code: 06/04/01/004'])\n",
      "downloaded  dict_keys(['ISOUKIRI 11/YEKOROGHA COMP PU Code: 06/04/01/003'])\n",
      "downloaded  dict_keys(['OCKIYA EWOAMA/IWOAMA SQUARE PU Code: 06/04/01/002'])\n",
      "downloaded  dict_keys(['ISOUKIRI 1/ISOUKIRI VILLAGE SQUARE PU Code: 06/04/01/001'])\n",
      "downloaded  dict_keys(['CHIEF AMANGI/CHIEF AMANGI SQUARE PU Code: 06/04/02/014'])\n",
      "downloaded  dict_keys(['SEKIAPU WARI/SEKIAPU WARI SQUARE PU Code: 06/04/02/013'])\n",
      "downloaded  dict_keys(['CHIEF KUKU/CHIEF KUKU SQUARE PU Code: 06/04/02/012'])\n",
      "downloaded  dict_keys(['PONI POLO11/ARUWARI SQUARE PU Code: 06/04/02/011'])\n",
      "downloaded  dict_keys(['PONI POLO/PONI POLO SQUARE PU Code: 06/04/02/010'])\n"
     ]
    }
   ],
   "source": [
    "download_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
